{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Optimization?\n",
    "\n",
    "**Optimization** means finding the \"best\" solution among a set of possible options. Imagine you want to find the lowest point of a hill (minimization) or the highest point of a mountain (maximization). In mathematical terms, we often try to find the minimum or maximum value of a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Optimization?\n",
    "\n",
    "**Optimization** means finding the \"best\" solution among a set of possible options. Imagine you want to find the lowest point of a hill (minimization) or the highest point of a mountain (maximization). In mathematical terms, we often try to find the minimum or maximum value of a function.\n",
    "\n",
    "### Why use Optimization?\n",
    "\n",
    "There are many real-world problems where we want to optimize something:\n",
    "\n",
    "- Minimizing cost in manufacturing\n",
    "- Maximizing profits in business\n",
    "- Finding the most efficient design of a structure\n",
    "\n",
    "So, optimization techniques are the tools we use to get these \"best\" values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy's Role in Optimization\n",
    "\n",
    "SciPy is a Python library that provides easy-to-use tools for optimization through the `scipy.optimize` module. With this module, we can solve optimization problems in a very simple and structured way.\n",
    "\n",
    "### Starting Point: The `minimize()` Function\n",
    "\n",
    "The **most basic** function in SciPy for optimization is `minimize()`. This function helps us find the minimum of a mathematical function. You can think of it like this:\n",
    "\n",
    "- You have a function \\( f(x) \\), and you want to find the value of `x` where this function gives the smallest value.\n",
    "\n",
    "### Basic Terminology\n",
    "\n",
    "- **Objective function**: This is the function that you want to minimize or maximize.\n",
    "- **Initial guess**: You start with an initial guess (value of `x`), and SciPy will improve this guess iteratively.\n",
    "- **Minimum**: The point where the function gives the lowest value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: A Simple Parabola\n",
    "\n",
    "Let’s start with the **simplest case**. Suppose we want to minimize a function like this:\n",
    "\n",
    "\\[\n",
    "f(x) = x^2 + 3x + 2\n",
    "\\]\n",
    "\n",
    "This is a simple quadratic function, a parabola. We want to find the value of `x` where the function reaches its lowest point. In simple words, we want to find the minimum value of this curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: -0.25\n",
      "        x: [-1.500e+00]\n",
      "      nit: 2\n",
      "      jac: [ 0.000e+00]\n",
      " hess_inv: [[ 5.000e-01]]\n",
      "     nfev: 6\n",
      "     njev: 3\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "def objective(x):\n",
    "    return x**2 + 3*x + 2\n",
    "x0 = 0  # Let's start with an initial guess of x = 0\n",
    "result = minimize(objective, x0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through the code line by line:\n",
    "\n",
    "- **`objective(x)`**: This is the function we are minimizing, and it takes a single input `x`. It returns \\( x^2 + 3x + 2 \\).\n",
    "- **`x0 = 0`**: This is the starting point (our initial guess) for the optimizer.\n",
    "- **`minimize(objective, x0)`**: The `minimize()` function tries to find the value of `x` where the `objective()` function is the smallest.\n",
    "\n",
    "After running the code, SciPy will tell you the value of `x` where the function reaches its minimum. The output might look something like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy tells us that the optimal value of x is approximately -1.5, which is the point where the function has its minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with the function \\( f(x) = x^2 + 3x + 2 \\). SciPy's minimize() function tries different values of x and sees which one makes the function smallest. It tells us that at \\( x = -1.5 \\), the function reaches its lowest value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Optimizers in SciPy\n",
    "\n",
    "Now that we know how to use the `minimize()` function, let’s look at the **different methods** SciPy uses to minimize functions. These methods are different techniques that SciPy uses behind the scenes to find the minimum value. You can specify the method like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(objective, x0, method='BFGS')  # Using the BFGS method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some common methods:\n",
    "\n",
    "1. **Nelder-Mead**: Best for non-smooth functions (simplex method).\n",
    "2. **BFGS**: A quasi-Newton method, useful for smooth functions.\n",
    "3. **CG**: Conjugate gradient method.\n",
    "4. **L-BFGS-B**: Like BFGS but supports bounds (constraints on the values of `x`).\n",
    "5. **TNC**: Truncated Newton method.\n",
    "\n",
    "Each method has its own advantages, depending on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Basic Unconstrained Optimization**\n",
    "\n",
    "Let’s start with a **simple quadratic function**, which is an easy-to-understand example. We will minimize the following function:\n",
    "\n",
    "\\[\n",
    "f(x) = x^2 + 4x + 6\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of x: [-2.00000002]\n",
      "Minimum value of the function: 2.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function\n",
    "def objective(x):\n",
    "    return x**2 + 4*x + 6\n",
    "\n",
    "# Initial guess\n",
    "x0 = 0  # Start with an initial guess of x = 0\n",
    "\n",
    "# Minimize the objective function\n",
    "result = minimize(objective, x0)\n",
    "\n",
    "print(\"Optimal value of x:\", result.x)\n",
    "print(\"Minimum value of the function:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objective Function**: \\( f(x) = x^2 + 4x + 6 \\).\n",
    "- The goal is to find the value of `x` that gives the minimum value of the function.\n",
    "- **Output**:\n",
    "    - The optimal value of `x`.\n",
    "    - The function value at that minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Unconstrained Optimization with Multiple Variables**\n",
    "\n",
    "Now, let’s move to a problem with **multiple variables**. Consider the following function:\n",
    "\n",
    "\\[\n",
    "f(x, y) = (x - 1)^2 + (y - 2.5)^2\n",
    "\\]\n",
    "\n",
    "We aim to minimize this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values of x and y: [0.99999996 2.50000001]\n",
      "Minimum value of the function: 1.968344227868139e-15\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function with multiple variables\n",
    "def objective(vars):\n",
    "    x, y = vars\n",
    "    return (x - 1)**2 + (y - 2.5)**2\n",
    "\n",
    "# Initial guess for x and y\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "# Minimize the objective function\n",
    "result = minimize(objective, initial_guess)\n",
    "\n",
    "print(\"Optimal values of x and y:\", result.x)\n",
    "print(\"Minimum value of the function:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Objective Function**: A function of two variables, \\( x \\) and \\( y \\).\n",
    "- The function reaches its minimum when `x` is close to `1` and `y` is close to `2.5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constrained Optimization with Bounds**\n",
    "\n",
    "Let’s impose constraints on our variables. For example, we’ll minimize the same function as above but limit `x` to be between `0` and `2`, and `y` between `0` and `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values of x and y with bounds: [0.99999999 2.50000001]\n",
      "Minimum value of the function with bounds: 1.9157760588045425e-16\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function\n",
    "def objective(vars):\n",
    "    x, y = vars\n",
    "    return (x - 1)**2 + (y - 2.5)**2\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "# Bounds for x and y\n",
    "bounds = [(0, 2), (0, 3)]  # x in [0, 2] and y in [0, 3]\n",
    "\n",
    "# Minimize with bounds\n",
    "result = minimize(objective, initial_guess, bounds=bounds)\n",
    "\n",
    "print(\"Optimal values of x and y with bounds:\", result.x)\n",
    "print(\"Minimum value of the function with bounds:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bounds**: These are constraints on `x` and `y` such that they cannot go beyond a certain range.\n",
    "- The optimizer respects these boundaries and finds the minimum within them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nonlinear Constraint Optimization**\n",
    "\n",
    "Let’s make things more interesting by adding **nonlinear constraints**. Suppose we want to minimize the following function:\n",
    "\n",
    "\\[\n",
    "f(x, y) = x^2 + y^2\n",
    "\\]\n",
    "\n",
    "subject to the constraint:\n",
    "\n",
    "\\[\n",
    "x + y \\geq 1\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values of x and y with constraint: [0.5 0.5]\n",
      "Minimum value of the function with constraint: 0.5\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function\n",
    "def objective(vars):\n",
    "    x, y = vars\n",
    "    return x**2 + y**2\n",
    "\n",
    "# Nonlinear constraint (x + y should be >= 1)\n",
    "def constraint(vars):\n",
    "    x, y = vars\n",
    "    return x + y - 1\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [0.5, 0.5]\n",
    "\n",
    "# Constraint dictionary\n",
    "nonlinear_constraint = {'type': 'ineq', 'fun': constraint}\n",
    "\n",
    "# Minimize with a nonlinear constraint\n",
    "result = minimize(objective, initial_guess, constraints=[nonlinear_constraint])\n",
    "\n",
    "print(\"Optimal values of x and y with constraint:\", result.x)\n",
    "print(\"Minimum value of the function with constraint:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Constraint**: The constraint is defined as a separate function where the output should be non-negative. Here, `x + y - 1 >= 0` is the constraint.\n",
    "- The optimizer finds the minimum value that satisfies this constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optimization with Jacobian (Gradient Information)**\n",
    "\n",
    "Using gradient (Jacobian) information can speed up the optimization. Let’s optimize:\n",
    "\n",
    "\\[\n",
    "f(x) = x^4 - 3x^3 + 2\n",
    "\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of x with gradient: [2.25]\n",
      "Minimum value of the function with gradient: -6.54296875\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function\n",
    "def objective(x):\n",
    "    return x**4 - 3*x**3 + 2\n",
    "\n",
    "# Derivative (gradient) of the objective function\n",
    "def gradient(x):\n",
    "    return 4*x**3 - 9*x**2\n",
    "\n",
    "# Initial guess\n",
    "x0 = 2.0\n",
    "\n",
    "# Minimize with gradient information\n",
    "result = minimize(objective, x0, jac=gradient, method='BFGS')\n",
    "\n",
    "print(\"Optimal value of x with gradient:\", result.x)\n",
    "print(\"Minimum value of the function with gradient:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Jacobian**: The derivative (gradient) is provided using the `jac` parameter. This makes optimization more efficient.\n",
    "- **BFGS**: A popular method for gradient-based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optimization with Equality Constraints**\n",
    "\n",
    "We can also define equality constraints. Suppose we have a problem like this:\n",
    "\n",
    "Minimize \\( f(x, y) = (x - 3)^2 + (y - 4)^2 \\)\n",
    "\n",
    "Subject to the constraint: \\( x + y = 7 \\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values of x and y with equality constraint: [3. 4.]\n",
      "Minimum value of the function with equality constraint: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Objective function\n",
    "def objective(vars):\n",
    "    x, y = vars\n",
    "    return (x - 3)**2 + (y - 4)**2\n",
    "\n",
    "# Equality constraint (x + y should be equal to 7)\n",
    "def equality_constraint(vars):\n",
    "    x, y = vars\n",
    "    return x + y - 7\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [2, 5]\n",
    "\n",
    "# Constraint dictionary\n",
    "eq_constraint = {'type': 'eq', 'fun': equality_constraint}\n",
    "\n",
    "# Minimize with an equality constraint\n",
    "result = minimize(objective, initial_guess, constraints=[eq_constraint])\n",
    "\n",
    "print(\"Optimal values of x and y with equality constraint:\", result.x)\n",
    "print(\"Minimum value of the function with equality constraint:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Equality Constraint**: We ensure that `x + y` is exactly `7`.\n",
    "- The optimizer finds the solution that both minimizes the objective function and satisfies this equality constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Global Optimization Using Differential Evolution**\n",
    "\n",
    "When dealing with complex functions, finding the global minimum (not just local minimum) is crucial. **Differential Evolution** is a global optimizer available in SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global minimum of the function: [-2.33005857]\n",
      "Minimum value of the function using global optimization: -29.13604486788894\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import differential_evolution\n",
    "\n",
    "# Objective function with multiple local minima\n",
    "def objective(x):\n",
    "    return x**4 - 10*x**2 + 4*x + 5\n",
    "\n",
    "# Bounds for x\n",
    "bounds = [(-10, 10)]  # Search in the range of -10 to 10\n",
    "\n",
    "# Use differential evolution for global optimization\n",
    "result = differential_evolution(objective, bounds)\n",
    "\n",
    "print(\"Global minimum of the function:\", result.x)\n",
    "print(\"Minimum value of the function using global optimization:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Differential Evolution**: A method for global optimization that searches over a specified range.\n",
    "- It’s useful for functions with multiple local minima where traditional methods might get \"stuck.\"\n",
    "\n",
    "These examples provide a comprehensive view of different optimization scenarios in SciPy, from the simplest problems to more advanced, constrained, and global optimization challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
